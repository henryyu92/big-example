## 分布式一致性算法
### 2PC(2-Phase Commit)
二阶段提交协议，即将事务的提交过程分为两阶段处理：准备阶段和提交阶段。事务的发起者称为协调者，事务的执行者称为参与者
#### 准备阶段
- 协调者向所有参与者发送事务执行请求，并等待所有参与者回复
- 各参与者执行事务操作，将 undo 和 redo 信息记录到事务日志中，但不提交事务
- 如果参与者事务执行成功则向协调者反馈 Yes，否则反馈 No；
#### 提交阶段
如果所有参与者都返回 Yes 说明可以正常执行事务，则提交事务：
- 协调者向所有参与者发起正式提交事务(commit)的请求；
- 参与者执行 commit，成功后释放整个事务期间锁住的资源；
- 参与者向协调者反馈执行完成的 ACK 消息；
- 协调者接收到所有的参与者的 Ack 消息后，完成事务的提交；

如果有参与者返回 No 或者协调者等待超时仍有参与者未返回结果，则中断事务：
- 协调者向所有参与者发起事务回滚请求(rollback)；
- 参与者使用 undo 信息执行回滚，并释放整个事务期间锁住的资源；
- 各参与者向协调者发送 Ack 消息；
- 协调者收到所有参与者的 ACK 消息后，完成事务的中断；

二阶段提交协议原理简单、易于实现，但是二阶段提交协议存在严重的缺陷：
- 同步阻塞：执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态
- 单点故障：协调者存在单点问题，如果协调者故障，则所有的参与者将一直处于锁定状态
- 脑裂：如果只有部分参与者接收并执行了 commit，则会导致节点数据不一致

### 3PC(3-Phase Commit)
三阶段提交协议，通过在协调者和参与者中引入超时机制来克服二阶段提交协议造成的阻塞和单点问题。三阶段提交协议将事务的提交过程分为三个阶段：CanCommit、PreCommit、doCommit。
#### CanCommit
- 协调者向所有参与者发送包含事务内容的 CanCommit 请求，询问是否可以提交事务，并进入 Prepare 阶段等待所有参与者的回复；
- 参与者收到 CanCommit 请求后，如果认为可以执行事务操作，则返回 Yes 并进入预备状态，否则返回 No；
#### PreCommit
如果所有的参与者都返回 Yes，则表示可以执行事务：
- 协调者向参与者发出 PreCommit 请求，进入准备阶段；
- 参与者接收到 PreCommit 请求后执行事务操作，将 undo 和 redo 信息记录到事务日志中，但不提交事务；
- 如果参与者事务执行成功，则向协调者反馈 Yes；否则反馈 No；

如果任一参与者返回 No，或者协调者等待超时仍没有接收到参与者的响应，则中断事务：
- 协调者向所有参与者发送 Abort 请求；
- 参与者接收到协调者发送的 Abort 请求或者参与者等待超时之后仍未收到协调者的请求，则执行事务的中断

#### doCommit
如果 PreCommit 阶段参与者返回 Yes 则表示可以参与者正常执行事务，此时发送事务提交通知：
- 协调者从预提交状态进入提交状态，向所有的参与者发送 doCommit 请求；
- 参与者接收到 doCommit 请求后会正式提交事务，并且释放锁住的资源；
- 参与者向协调者返回执行完成的 Ack 消息；
- 协调者接收到所有参与者的 Ack 消息后完成事务的提交；

如果任一参与者返回 No 或者协调者等待超时之后仍没有收到参与者的响应，则发起中断事务：
- 协调者向所有的参与者发出 Abort 请求；
- 参与者接收到 Abort 请求后利用 undo 信息执行事务回滚操作，并且释放锁住的资源；
- 各参与者向协调者反馈回滚完成 Ack 消息；
- 协调者收到所有参与者的 Ack 消息后完成事务的中断；

**在 doCommit 阶段，无论协调者故障或者由于网络分区原因，都会导致参与者无法接收到协调者发出的 doCommit 消息或者 Abort 消息，此时参与者会在等待超时后继续执行事务的提交操作**

3PC 通过引入超时机制降低阻塞范围，协调者和参与者会在等待超时后中断事务；避免协调者单点问题，参与者在 doCommit 阶段超时后自动提交事务。但是 3PC 仍然存在脑裂问题，由于网络分区原因，部分参与者未能接收到协调者的 Abort 请求则会在等待超时后自动提交事务，从而导致数据不一致；
### Paxos
Paxos 算法解决了分布式系统中各个进程就某个值达成一致的问题。Paxos 算法利用大多数机制保证了 2F+1 的容错能力，即 2F+1 个节点的系统最多允许 F 个节点同时出现故障。

Paxos 算法中有三个角色，在多副本状态机中每个副本允许同时具有这三种角色：
- Proposer：提出提案(Proposal)，提案包括提案编号 n 和提案的值 v
- Acceptor：可以接受(Accept)提案，若 Proposal 得到大多数的 Acctptor 接受则表示该提案被批准(Chosen)
- Learner：只能学习已经达成一致(Chosen)的提案

为了保证能够最终达成一致，Paxos 定义了几个约束：
- Acceptor 必须接受(Accept)它接收到的第一个提案(Proposal)
- 一旦值为 v 的提案被选定(Chosen)，之后任何 Acceptor 再次接受(Accept)的提案的值一定为 v
- 一旦值为 v 的提案被选定(Chosen)，之后任何 Proposer 提出的提案(Proposal) 的值一定为 v
- 如果一个编号为 n 的提案的值为 v，那么存在一个多数派集合，要么集合中所有 Acceptor 没有接受(Accept)编号小于 n 的任何提案，要么集合中的 Acceptor 已经接受(Accept) 的所有编号小于 n 的提案中编号最大的那个提案的值为 v

Paxos 算法分为 Prepare 阶段和 Accept 阶段：
#### Prepare 阶段
- Proposer 生成一个编号为 n 的提案，向大多数 Acceptor 广播 Prepare(n) 的请求，该广播请求不携带提案值 v
- Acceptor 接收到 Prepare(n) 的请求后判断编号 n 是否比之前已经响应过的所有的提案(Proposal)的编号大：如果是则将之前已经 Accept 的最大编号的提案(若此时还没有已接受的提案，则提案值 v 为空)反馈给 Proposer，并承诺不再接受(Accept)任何编号小于 n 的提案；如果不是则不理会
#### Accept 阶段
- 如果一段时间后 Proposal 收到的响应小于 Accptor 的一半，则尝试生成更大编号的提案，再次向 Acceptor 广播
- 如果 Proposer 收到半数以上的 Acceptor 响应后：
  - 如果所有响应都包含提案值 v，那么将提案编号 n 和提案的值作为提案发送 Accept 请求给 Acceptor；
  - 如果响应中包含提案值 v，那么将编号 n 与收到的响应中编号最大的提案的值作为提案发送 Accept 请求给Acceptor
- Acceptor 收到编号为 n 的 Accept 请求，只要 Acceptor 之前响应的提案的编号小于 n 则接受这个提案并响应 Proposer；如果 n 小于 Acceptor 之前接受的提案的编号则不回复
- Proposer 统计 Acceptor 的回复，如果提交成功回复的数量大于 Acceptor 的一半，则表示达成一致，此时向所有的 Proposer、Learner 广播已经达成一致的提案；如果不足一半则生成编号更大的提案重新广播给 Acceptor

Learner 学习被选定的 value有三种方案：
- 一旦 Acceptor 接受了某个提案，即将该提案发送给所有的 Learner，通信次数为 M*N
- Acceptor 将接受的提案，发给主Learner，由主Learner分发给其他Learner，通信次数为 M+N+1，存在单点问题
- Acceptor 将接受的提案，发给主Learner组，由主Learner组分发给其他Learner

### Zab
- Zab 协议的核心
  > <p>所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为 Leader服务器，而余下的其他服务器则成为 Follower 服务器。 Leader 服务器负责将一个客户端事务请求转换成一个事务proposal（提议），并将该 Proposal分发给集群中所有的Follower服务器。之后 Leader 服务器需要等待所有Follower 服务器的反馈,一旦超过半数的Follower服务器进行了正确的反馈后，那么 Leader 就会再次向所有的 Follower服务器分发Commit消息，要求其将前一个proposal进行提交。</p>
  > <p>这种事务处理方式与2PC（两阶段提交协议）区别在于，两阶段提交协议的第二阶段中，需要等到所有参与者的"YES"回复才会提交事务，只要有一个参与者反馈为"NO"或者超时无反馈，都需要中断和回滚事务。</p>
- Zab 协议介绍
  > <p>ZAB 协议包括两种基本的模式，分别是崩溃恢复和消息广播。</p>
  > <p>当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时， ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的Leader 服务器同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。</p>
  > <p>当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播 ， 那么新加人的服务器就会自觉地进人数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。</p>
- 消息广播
  > <p>在 ZAB 协议的二阶段提交过程中，移除了中断逻辑，所有的 Follower 服务器要么正常反馈 Leader 提出的事务 Proposal ,要么就抛弃Leader 服务器。同时， ZAB 协议将二阶段提交中的中断逻辑移除意味着我们可以在过半的 Follower 服务器已经反馈 Ack 之后就开始提交事务 Proposal 了，而不需要等待集群中所有的 Follower 服务器都反馈响应。这种简化了的二阶段提交模型无法处理 Leader 服务器崩溃退出而带来的数据不一致问题，此时采用崩溃恢复模式来解决这个问题。</p>
  > <p>在整个消息广播过程中， Leader 服务器会为每个事务请求生成对应的 Proposal来进行广播，并且在广播事务 Proposal 之前， Leader 服务器会首先为这个事务 Proposal 分配一个全局单调递增的唯一事务ID (即 ZXID )。</p>
  > <p>Leader 服务器会为每一个 Follower 服务器都各自分配一个单独的队列，然后将需要广播的事务 Proposal 依次放入这些队列中去，并且根据 FIFO策略进行消息发送。每一个 Follower 服务器在接收到这个事务 Proposal 之后，都会首先将其以事务日志的形式写入到本地磁盘中去，并且在成功写入后反馈给 Leader 服务器一个 Ack 响应。当 Leader 服务器接收到超过半数 Follower 的 Ack 响应后，就会广播一个Commit 消息给所有的 Follower 服务器以通知其进行事务提交，同时 Leader 自身也会完成对事务的提交。</p>
- 崩溃恢复
  > <p>Leader 服务器出现崩溃，或者说由于网络原因导致 Leader 服务器失去了与过半 Follower 的联系，那么就会进入崩溃恢复模式。</p>
  > <p>崩溃恢复中的场景和zab协议需要保证的特性:</p>
  > 1. ZAB 协议需要确保那些已经在 Leader 服务器上提交的事务最终被所有服务器都提交
    > <p>假设一个事务在 Leader 服务器上被提交了，并且已经得到过半 Follower 服务器的Ack 反馈，但是在它将 Commit 消息发送给所有 Follower 机器之前， Leader 服务器挂了，针对这种情况， ZAB 协议就需要确保该事务最终能够在所有的服务器上都被提交成功，否则将出现不一致。</p>
  > 2. ZAB协议需要确保丢弃那些只在 Leader 服务器上被提出的事务
    > <p>假设初始的 Leader 服务器 在提出了一个事务之后就崩溃退出了，导致集群中的其他服务器都没有收到这个事务，当该服务器恢复过来再次加入到集群中的时候 ，ZAB协议需要确保丢弃这个事务。</p>
  > <p>zookeeper 的选举算法能够保证 Leader 中的事务 Proposal 的 ZXID 最大，即 Leader 拥有所有已提交的事务 Proposal，因此只需要同步 Leader 和 Follower 的数据即可。</p>
  + 数据同步
    > <p>Leader 服务器会为每一个 Follower 服务器都准备一个队列，并将那些没有被各 Follower 服务器同步的事务以 Proposal 消息的形式逐个发送给 Follower 服务器，并在每一个 Proposal 消息后面紧接着再发送一个 Commit 消息，以表示该事务已经被提交。等到 Follower 服务器将所有其尚未同步的事务 Proposal 都从 Leader 服务器上同步过来并成功应用到本地数据库中后， Leader 服务器就会将该 Follower 服务器加入到真正的可用 Follower 列表中，并开始之后的其他流程。</p>
    > <p>下面来看 ZAB 协议是如何处理那些需要被丢弃的事务 Proposal 的。在 ZAB 协议的事务编号 ZXID 设计中， ZXID 是一个 64 位的数字，低 32 位可以看作是一个简单的单调递增的计数器，针对客户端的每一个事务请求， Leader 服务器在产生一个新的事务 Proposal 的时候，都会对该计数器进行加1操作；高 32 位代表了 Leader 周期 epoch 的编号，每当选举产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务 Proposal 的 ZXID ,并从该 ZXID 中解析出对应的 epoch 值，然后再对其进行加1操作，之后就会以此编号作为新的 epoch, 并将低 32 位置0来开始生成新的 ZXID 。</p>
    > <p>基于这样的策略，当一个包含了上一个 Leader 周期中尚未提交过的事务 Proposal的服务器启动加入到集群中，发现此时集群中已经存在leader，将自身以Follower 角色连接上 Leader 服务器之后， Leader 服务器会根据自己服务器上最后被提交的 Proposal来和 Follower 服务器的 Proposal进行比对，发现follower中有上一个leader周期的事务Proposal时，Leader 会要求 Follower 进行一个回退操作——回退到一个确实已经被集群中过半机器提交的最新的事务 Proposal 。<p>

 
### raf
> Raft和Paxos均只要保证n/2+1节点正常即可服务。相比Paxos，其优势即为易于理解和实现。Raf将算法分解为：选择领导者、日志复制、安全性等几个子问题。它的流程即为：开始时在集群中选举出Leader负责日志复制的管理，Leader接收来自客户端的事务请求（日志），并将它们复制给集群中的其他节点，然后通知集群中的其他节点提交日志，Leader负责保证其他节点与它的日志同步。当Leader宕机时，集群其他节点重新发起选举，选出的新的Leader。
- 角色
    + Learder：负责处理来自客户端的请求，管理日志复制、以及与Follower保持心跳以维持其领导者地位
    + Follower：负责响应来自Leader的日志复制请求，响应来自Candidate的选举请求。初始时所有节点均为Follower
    + Candidate：负责发起选举投票，Raft启动后或Leader宕机后，一个节点从Follower转为Candidate，并发起选举，选举成功后，由Candidate转为Leader。
- Term
  > Raft 中有 Term 的概念，一轮选举即为一个 Term，一个 Term 中只能产生一个 Leader。Term 使用连续递增的编号表示，初始时所有 Follower 的 Term 均为 1。
- 选举
- 日志复制
- 安全性