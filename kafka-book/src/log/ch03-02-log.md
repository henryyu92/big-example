## 日志

消息在 Kafka 集群中以追加日志的方式存储在磁盘，每个分区都有对应的日志文件，日志文件位于配置参数 `log.dir` 指定的目录下的 `<topic>-<partition>` 目录中。每个分区对应的目录下有多个日志文件，日志文件以其中包含的第一个消息的 offset 命名。
```
集群主题比较多，分区比较多是会导致文件很多，消息写入的时候写入多个文件夹，不再是顺序写了
```

### Log

Log 是 Kafka 日志的实现，客户端发送的消息通过 Log 实现持久化存储。

Log 由多个分段 (Segment) 组成，每个分段负责维护部分消息数据。分段中只有一个处于活跃状态 (activeSegment) 用于消息的追加，当处于活跃状态的分段达到阈值条件后会滚动创建新的分段。
<center>

![Log](../img/log.png)

日志分段是 Kafka 中最基本的数据存储单元，每个分段对应着一个物理文件。


### 消息追加

客户端发送的消息在追加到 Log 时会追加到其中活跃的 Segment，当 Segment 的大小达到阈值之后会滚动创建一个新的 Segment 并且关闭之前的 Segment。

集群接收的消息由 Log 追加到 Segment 中，，当 segment 的大小到达阈值大小之后，会滚动新建一个日志分段（segment）保存新的消息，而分区的消息总是追加到最新的日志分段（也就是 activeSegment）中。每个日志分段都会有一个基准偏移量（segmentBaseOffset，或者叫做 baseOffset），这个基准偏移量就是分区级别的绝对偏移量，而且这个值在日志分段是固定的。有了这个基准偏移量，就可以计算出来每条消息在分区中的绝对偏移量，最后把数据以及对应的绝对偏移量写到日志文件中。




### 日志切分
消息在追加到活跃分段时会计算当前日志是否需要切分新的分段，

切分的 `LogSegment` 以日志文件的形式持久到磁盘，日志文件名为当前 `LogSegment` 中第一条消息的 `offset`。





日志分段文件在一定条件会切分，相对应的索引文件也需要切分。日志分段文件切分包含以下一条即可触发切分：
- 当前日志分段文件的大小超过了 broker 端参数 ```log.segment.bytes``` 配置的值，默认是 1073741824(1GB)
- 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 ```log.roll.ms``` 或 ```log.roll.hours``` 参数配置的值(log.roll.ms 优先级大于 log.roll.hours)，默认情况下只配了 ```log.roll.hours``` 值为 168(7 天)
- 偏移量索引文件或时间戳索引文件的大小达到 broker 端参数 ```log.index.size.max.bytes``` 配置的值，默认是 10485760(10MB)
- 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE，即 ```offset - baseOffset > Integer.MAX_VALUE```
