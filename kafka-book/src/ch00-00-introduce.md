# Kafka 介绍

Kafka 是一个高性能、高吞吐的分布式事件流平台，通过发布/订阅(`Publish/Subscribe`) 的方式将数据从一个系统传输到另一个系统。Kafka 提供了数据持久化的功能，并通过多副本的方式保证数据的可靠，此外 Kafka 还能保证消息的顺序性以及消息的回溯消费。

- **消息持久化**：Kafka 依赖文件系统持久化消息，数据的持久化采用对文件的追加实现，时间复杂度为 O(1)，因此即使是存储海量的消息也不会影响性能
- **高吞吐量**：Kafka 顺序写数据的同时采用零拷贝(zero-copy)技术，采用 sendFile() 函数在内核中操作两个文件描述符之间直接传递数据而避免了内核缓冲区与用户缓冲区之间的数据拷贝，同时 Kafka 还支持数据压缩和批量发送以及多分区是的 Kafka 的吞吐量达到每秒百万级别
- **扩展性**：Kafka 使用 Zookeeper 对集群进行协调管理，生产者、消费者和代理都可以配置多个，同时在集群扩展时不需要停机，集群能够自动感知并重新进行负载均衡和数据复制。
- **数据备份**：Kafka 可以为每个主题指定副本数对数据进行持久化备份，可以一定程度上防止数据丢失提高可用性
- **轻量级**：Kafka 代理是无状态的，即代理不记录消息是否消费，消费偏移量有消费者自己维护，同时集群本身几乎不需要生产者和消费者的状态信息

## 架构

Kafka 是由以 TCP 网络互相通信的 Server 和 Client 建立起来的分布式系统，其运行时架构如下：

- **生产者**：负责将消息发送到 `Broker` 的客户端
- **消费者**：负责接收 `Broker` 消息的客户端
- **Broker**：Kafka 集群的一个实例，负责消息的存储，每个 `Broker` 在集群中有一个由参数 `broker.id` 指定的 id
- **ZooKeeper**：Kafka 利用 ZooKeeper 维护元数据信息以及控制器选举等操作

## 术语

Kafka 可以很好的替代传统的消息队列，但是和传统的消息队列不同的是 Kafka 具有更高的吞吐量，内置的分区、复制和容错能力使得其能够满足大规模的消息处理场景。

**消息(Record)**

消息是 Kafka 的基本单位，消息由生产者产生并发送到 `Broker`，最后由消费者消费。消息由定长的消息头和变长的消息体构成，每条消息称为一个 Record。

**主题(Topic)**

Kafka 将一组消息抽象为主题(Topic)，也就是说主题对应一个消息的分类，每个消息都属于某个特定的主题，生产者将消息发送到特定主题消费者订阅主题进行消费。

**分区(Partition)**

主题是 Kafka 中的逻辑概念，主题可以划分为多个分区，每个分区只属于单个主题，因此分区也称为主题分区(`TopcPartition`)。

每个主题被分为一个或多个分区(Partition)，每个分区由一系列有序、不可变的消息组成，是一个有序队列。每个分区在物理上对应一个文件夹，文件夹命名格式为 ```TopicName_partitionNo```。

每个分区在物理上对应一个文件夹，归属同一个主题的消息存储在不同的分区，消费者订阅主题时会到指定的分区消费消息。

Kafka 只能保证一个分区内的消息是有序的，不能保证分区间消息的有序性。每条消息是追加到分区中，由于是顺序写磁盘因此效率非常高；Kafka 消息消费之后不会立即删除，Kafka 提供了基于存储时间和基于分区长度两种删除消息的策略，可以通过配置文件设置。

分区使得 Kafka 在并发处理上变得更加容易，理论上说分区越多吞吐量越大，分区也是 Kafka 保证消息被顺序消费以及对消息进行负载均衡的基础；

**副本(Replica)**

Kafka 通过多副本机制提升数据的可靠性，每个分区都会有多个副本(Replica)，不同的副本保存在不同的 broker 中(broker 数量不少于副本数)。分区副本中 leader 副本负责消息的读取，follower 副本负责同步 leader 副本上的数据，当 leader 故障时从 follower 副本中选举出新的 leader 副本实现故障转移(`fali over`)。

Kafka 分区副本之间采用 `leader/follower` 机制保证数据的一致性，Kafka 从分区的副本中选举出 leader 负责处理客户端的读写请求，其他的作为 follower 同步 leader 的数据，如果 leader 失效则从 follower 中选举选出新的 leader 对外提供服务。

分区副本一般会部署在不同的节点上，由于网络延迟会出现数据同步延迟的问题，为了保证数据的一致性，Kafka 将副本集合分为三类：

- **AR(Assigned Replicas)**：分区的所有副本
- **ISR(In-Sync Replicas)**：与 leader 副本同步延迟在范围内的副本集合
- **OSR(Out-of-Sync Replicas)**：与 leader 副本同步延迟超出范围的副本集合

Kafka 使用 ZooKeeper 维护 ISR 集合，leader 负责将保持消息同步的副本加入到 ISR 集合。Kafka 规定只有写入了 ISR 集合的消息才认为写入成功，因此 ISR 集合的大小以及副本间的同步速度决定了消息写入的性能。默认情况下，当 leader 失效时只有在 ISR 集合中的副本才有可能被选举为新的 leader。

**偏移量(Offset)**

任何发送到分区的消息都是直接追加到日志文件(分区目录下以 .log 结尾的文件)的尾部，每条消息在日志文件中的位置都会对应一个按序递增的偏移量。**偏移量在一个分区下是严格递增的逻辑值，不表示消息在磁盘的物理地址**。Kafka 不会为偏移量提供额外的索引机制，消费者通过控制消息的偏移量对消息进行消费，消费者对偏移量的操作不会影响消息本身的偏移量。

消息在 Kafka 中是以追加的形式存储的，每个分区的消息会分配一个严格递增的偏移量(`offset`)。偏移量是一个逻辑值，对消息偏移量的操作不会影响其本身的偏移量。

Kafka 没有为偏移量提供索引机制，但是通过偏移量可以实现消息在分区内的顺序性以及特定消息的消费。

Kafka 的数据日志被划分为多个日志段(LogSegment)，日志段是 Kafka 日志对象分片的最小单位，和日志对象(Log)一样也是逻辑概念。一个日志段对应磁盘上一个具体的日志文件(.log 结尾，用于保存消息实际数据)和两个索引文件(分别以 .index 结尾的消息偏移量索引文件和以 .timeindex 结尾的消息时间戳索引文件)

**HW & LEO**

**HW(High Watermark)** 表示分区中第一个不可以消费的消息的偏移量(offset)，**LEO(Log End Offset)** 表示分区中下一个写入的消息的偏移量(offset)。

分区中的每个副本都会维护自己的 HW 和 LEO，因此 ISR 集合中最小的 LEO 即为分区的 HW。


## 部署

Kafka 集群由生产者、消费者、Broker 和 ZooKeeper 组成，其中生产者和消费者与业务绑定，因此不需要独立部署。ZooKeeper 集群通常作为集群管理、Master 选举、分布式协调组件被各个不同的业务公用，因此也不需要独立部署。

**Docker**

### 参数配置

Kafka 集群启动时会读取 `$KAFKA_HOME/config/server.properties` 文件中设置的参数，通过对这些参数的调优能够使得 Kafka 集群获得更好的性能。

- **`zookeeper.connect`**：指定 broker 需要连接的 ZooKeeper 集群的地址(包含端口号)，使用逗号 (,) 隔开集群的多个节点地址。在集群地址上增加一个 chroot 路径 (如 `localhost:2181/kafka`) 指定 Kafka 数据存储的根路径，可以使得 ZooKeeper 能够以多租户的方式为不同的业务提供服务
- **`listeners`**：指定 broker 监听客户端连接的地址列表，格式为 `protocol://hostname:port`，只有指定的客户端才能连接到 broker，默认值为 null 表示任意客户端可以连接。Kafka 支持三种协议：PLAINTEXT、SSL、SASL_SSL
- **`broker.id`**：指定当前 broker 的唯一标识，默认为 -1，即在集群启动时默认生成
- **`log.dir`**：指定 broker 存储数据的地址，默认为 `/tmp/kafak-logs`
- **`message.max.bytes`**：指定 broker 能接收的消息的最大值，默认为 1000012，超过指定大小的消息被发送到 broker 时会抛出 `RecordTooLargeException`

https://www.cnblogs.com/answerThe/p/11267129.html