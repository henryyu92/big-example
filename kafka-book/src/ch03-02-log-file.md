# 日志
Kafka 的消息在 broker 上以追加日志的形式存储，每个分区的每个副本在 broker 上都有各自的日志文件。日志文件位于 ```log.dirs``` 配置的目录下的 ```<topic>-<partitionId>``` 目录下。




broker 上的日志文件以及索引文件都是以基准偏移量(base offset)命名的，基准偏移量是一个 64 位的长整型数，表示当前日志文件中的第一条消息的 offset。


## Log

Log 是 kafka 日志的抽象，生产者向 broker 发送的消息是以 Log 的形式存储到文件中。Log 是一个 LogSegment 序列，每个 LogSegment 都有一个基准偏移量(base offset) 表示当前 LogSegment 中第一条消息的 offset。

Kafka 中消息不是一条一条的追加到日志文件中，而是以 ```RecordBatch``` 为单元追加的。消息在日志文件中是以二进制的形式存储的，


日志刷写

<center>

![Log](img/log.png)
</center>


日志分段文件在一定条件会切分，相对应的索引文件也需要切分。日志分段文件切分包含以下一条即可触发切分：
- 当前日志分段文件的大小超过了 broker 端参数 ```log.segment.bytes``` 配置的值，默认是 1073741824(1GB)
- 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 ```log.roll.ms``` 或 ```log.roll.hours``` 参数配置的值(log.roll.ms 优先级大于 log.roll.hours)，默认情况下只配了 ```log.roll.hours``` 值为 168(7 天)
- 偏移量索引文件或时间戳索引文件的大小达到 broker 端参数 ```log.index.size.max.bytes``` 配置的值，默认是 10485760(10MB)
- 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE，即 ```offset - baseOffset > Integer.MAX_VALUE```


### 磁盘存储
Kafka 依赖文件系统来存储消息，采用文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且不允许修改已写入的消息。
#### 页缓存
页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I/O 的操作。当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中，如果存在则直接返回；如果没有则操作系统会向磁盘发起读取请求并将读取的数据缓存入页缓存，之后再将数据返回给进程。

如果一个进程需要将数据写入磁盘，操作系统也会检测数据对应的页是否在页缓存中，如果不存在则先会在页缓存中添加相应的页，最后将数据写入对应的页，被修改的页变成了脏页操作系统会在合适的时候把脏页中的数据写入磁盘，以保证数据的一致性。

Kafka 中大量使用了页缓存，虽然消息都是先被写入页缓存然后由操作系统负责具体的刷盘任务，但 Kafka 也提供了同步刷盘及间断性强制刷盘的功能，这些功能可以通过 ```log.flush.interval.message``` 和 ```log.flush.interval.ms``` 来控制。

Linux 系统会使用磁盘的一部分作为 swap 分区，这样可以进行进程的调度：把当前非活跃的进程调入 swap 分区，以此把内存空出来让给活跃的进程。对于大量使用页缓存的 Kafka 而言，应当避免这种内存的交换，否则会对性能产生较大的影响。可以通过修改 ```vm.swappiness``` 参数(Linux 系统参数)来进行调节，```vm.swappiness``` 参数的上限为 100 表示积极地使用 swap 分区并把内存上的数据及时的搬运到 swap 分区；下限为 0 表示任何情况都不要发生交换，这样当内存耗尽时会终止某些进程。

### 日志同步机制
在分布式系统中，日志同步机制要保证数据一致性也要保证数据的顺序性。日志同步机制的一个基本原则是：如果客户端已经成功提交了某条消息，那么即使 leader 退出，也要保证新选出来的 leader 中能够包含这条消息。

Kafka 动态维护者一个 ISR 集合，处于 ISR 集合内的节点保持与 leader 相同的 HW，只有在 ISR 中的副本才有资格被选为新的 leader，位于 ISR 中的任何副本节点都有资格成为 leader。
